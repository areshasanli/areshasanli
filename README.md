## Hi, I'm Umud

Data Engineer building data systems for AI, analytics, and intelligent products.

### ðŸ”— Links

[Github](https://github.com/areshasanli)  Â·  [LinkedIn](https://www.linkedin.com/in/umudhasanli/)

### ðŸ’» Tech

<p>
  <img src="https://skillicons.dev/icons?i=python,postgres,redis,docker,fastapi,bash,linux,git,terraform,kafka&theme=dark" />
</p>

<p>
  <img src="https://img.shields.io/badge/-SQL-4479A1?style=flat&logo=postgresql&logoColor=white" />
  <img src="https://img.shields.io/badge/-Airflow-017CEE?style=flat&logo=apacheairflow&logoColor=white" />
  <img src="https://img.shields.io/badge/-Spark-E25A1C?style=flat&logo=apachespark&logoColor=white" />
  <img src="https://img.shields.io/badge/-Celery-37814A?style=flat&logo=celery&logoColor=white" />
  <img src="https://img.shields.io/badge/-dbt-FF694B?style=flat&logo=dbt&logoColor=white" />
  <img src="https://img.shields.io/badge/-Playwright-2EAD33?style=flat&logo=playwright&logoColor=white" />
</p>

### ðŸ‘· Experience

I'm a Data Engineer at [**HAL-X**](https://hal-x.com), an AI ecosystem company. Here's my [resume](https://www.linkedin.com/in/umudhasanli/).

I work on the data layer that powers AI products â€” building pipelines, preparing datasets, and making sure models get clean, validated, structured inputs. Most of my day-to-day involves construction cost data (Hal-Cost, IFC), dataset research, data quality, and turning messy real-world data into something production ML systems can actually use.

### ðŸ”§ Open Source

[**oxu-audio-scraper**](https://github.com/areshasanli/oxu-audio-scraper)

Distributed scraper that built a [850+ hour Azerbaijani audio news dataset](https://huggingface.co/datasets/mergenAI/oxu.az) for ASR/TTS training. Redis-backed job queue with 64 parallel workers, deduplication, and NVIDIA NeMo manifest output. Used in production for speech model training.

[**electroscrape-hub**](https://github.com/areshasanli/electroscrape-hub)

Production-grade multi-site product scraping system with round-robin scheduling, anti-blocking, and a centralized catalog that normalizes product data across 30+ sources into a unified schema. FastAPI + Celery + PostgreSQL.
